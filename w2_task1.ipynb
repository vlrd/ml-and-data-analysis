{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#task1, task2 \n",
    "file = open('sentense.txt', 'r')\n",
    "data=[]\n",
    "for line in file.readlines():\n",
    "    data.append(line.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task3\n",
    "import re\n",
    "nd=[]\n",
    "for line in data:\n",
    "    nd.append(re.split('[^a-z]', line))\n",
    "for line in nd:\n",
    "    while '' in line:\n",
    "        line.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for line in nd:\n",
    "    for word in line:\n",
    "        if word in all_words:\n",
    "            continue\n",
    "        else:\n",
    "            all_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_unique_words(all_words):\n",
    "    unique_words = []\n",
    "    for word in all_words:\n",
    "        if word in unique_words:\n",
    "            continue\n",
    "        else:\n",
    "            unique_words.append(word)\n",
    "    return unique_words\n",
    "\n",
    "len(get_unique_words(all_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task4\n",
    "arr = np.array(nd)\n",
    "w={}\n",
    "unique_words = get_unique_words(all_words)\n",
    "for word in unique_words:\n",
    "    w[word] = len(unique_words)\n",
    "    unique_words.remove(word)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task5\n",
    "array = np.zeros((22,254))\n",
    "for i in range(len(nd)):\n",
    "    for j in range(len(unique_words)):\n",
    "        array[i][j] = nd[i].count(unique_words[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#task6\n",
    "from scipy.spatial import distance\n",
    "dist = np.empty([22,1])\n",
    "for i in range(len(array)):\n",
    "    dist[i] = distance.cosine(array[0], array[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.]),\n",
       " array([0.77207885]),\n",
       " array([0.78178211]),\n",
       " array([0.79796949]),\n",
       " array([0.80481999]),\n",
       " array([0.83096915]),\n",
       " array([0.85714286]),\n",
       " array([0.85714286]),\n",
       " array([0.86636938]),\n",
       " array([0.87401184]),\n",
       " array([0.88603942]),\n",
       " array([0.88603942]),\n",
       " array([0.89517152]),\n",
       " array([0.89517152]),\n",
       " array([0.89898475]),\n",
       " array([0.89898475]),\n",
       " array([0.91091292]),\n",
       " array([0.92587507]),\n",
       " array([1.]),\n",
       " array([1.]),\n",
       " array([1.]),\n",
       " array([1.])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 4\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def word_count(word, line):\n",
    "    result = 0\n",
    "    for w in line:\n",
    "        if w == word:\n",
    "            result = result + 1\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_lines_and_words(file):\n",
    "    result_lines, result_words = [], []\n",
    "    with open(file, 'r') as f:\n",
    "        raw_lines = f.readlines()\n",
    "\n",
    "    for line in raw_lines:\n",
    "        line = line.lower()\n",
    "        split_words = [x for x in re.split('[^a-z]', line) if x != '']\n",
    "        result_lines.append(split_words)\n",
    "        result_words.extend(split_words)\n",
    "\n",
    "    result_words = set(result_words)\n",
    "    result_words = dict(zip([x for x in range(len(result_words))], result_words))\n",
    "    return result_lines, result_words\n",
    "\n",
    "\n",
    "def set_matrix(lines, words):\n",
    "    result = np.zeros((len(lines), len(words)))\n",
    "    for i in range(len(lines)):\n",
    "        for j in range(len(words)):\n",
    "            result[i, j] = word_count(words[j], lines[i])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_distincts(matrix, startV):\n",
    "    result = {}\n",
    "    \n",
    "    for i in range(0, startV):\n",
    "        result[i] = cosine(matrix[startV,], matrix[i])\n",
    "    \n",
    "    for i in range(startV + 1, len(matrix)):\n",
    "        result[i] = cosine(matrix[startV,], matrix[i])\n",
    "\n",
    "    return result      \n",
    "    \n",
    "\n",
    "LINES, WORDS = get_lines_and_words(\"sentense.txt\")\n",
    "C = set_matrix(LINES, WORDS)\n",
    "RES_DIC = get_distincts(C, 0)\n",
    "RES_SORT = sorted(RES_DIC.items(), key=lambda x: x[1])\n",
    "print(RES_SORT[0][0], RES_SORT[1][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
